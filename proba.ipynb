{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerko/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import datasets\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembed = model.get_output_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 694.0030, 2338.6108, 1067.6279,  ..., 1493.1703, 1461.0746,\n",
       "         456.2899], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unembed.forward(torch.tensor([float(i) for i in range(768)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.7654,  6.5866,  1.7553,  ...,  9.5762, 15.3242,  6.8427],\n",
       "       grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_layer_norm = model.base_model.ln_f\n",
    "unembed.forward(final_layer_norm.forward(torch.tensor([float(i) for i in range(768)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_2_dataset import GPT2Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "with open(\"datasets/dataset_test.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "data, input_ids, target_ids, attention_mask, target_index = next(iter(dataloader))\n",
    "#attention_mask[0][:target_index] = 1\n",
    "#print(data[0])\n",
    "#print(input_ids[0])\n",
    "#print(target_ids[0])\n",
    "#print(attention_mask[0])\n",
    "model.eval()\n",
    "output = model(input_ids, labels=target_ids, output_hidden_states=True, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is  tensor(3.8217, grad_fn=<NegBackward0>)\n",
      "predicted loss is  tensor(3.8217, grad_fn=<NllLossBackward0>)\n",
      "probabilities are  tensor([0.0720, 0.0393, 0.1288, 0.0006], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"loss is \", -torch.log(torch.softmax(output.logits[torch.arange(output.logits.shape[0]), target_index-1], dim=-1)[torch.arange(output.logits.shape[0]), target_ids[torch.arange(output.logits.shape[0]), target_index]]).mean())\n",
    "print(\"predicted loss is \", output.loss)\n",
    "print(\"probabilities are \", torch.softmax(output.logits[torch.arange(output.logits.shape[0]), target_index-1], dim=-1)[torch.arange(output.logits.shape[0]), target_ids[torch.arange(output.logits.shape[0]), target_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 13, 64, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = output.hidden_states\n",
    "hidden_states[-1].shape\n",
    "hs = torch.stack(hidden_states, dim = 1)\n",
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = unembed.forward(hs)\n",
    "logits_ = unembed.forward(final_layer_norm.forward(hs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 13, 64, 50257])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0720, 0.0393, 0.1288, 0.0006], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(logits[torch.arange(output.logits.shape[0]), -1, target_index-1], dim=-1)[torch.arange(output.logits.shape[0]), target_ids[torch.arange(output.logits.shape[0]), target_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is  tensor(3.8217, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"loss is \", -torch.log(torch.softmax(logits[torch.arange(output.logits.shape[0]), -1, target_index-1], dim=-1)[torch.arange(output.logits.shape[0]), target_ids[torch.arange(output.logits.shape[0]), target_index]]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tuned_lens.nn.lenses import TunedLens, LogitLens\n",
    "from tuned_lens.plotting import PredictionTrajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lens_model import Lens_model\n",
    "from lens import Lens, Logit_lens, Linear_lens\n",
    "\n",
    "lens_4 = Linear_lens.from_model(model)\n",
    "lens_8 = Linear_lens.from_model(model)\n",
    "lens_model = Lens_model([lens_4, lens_8], layers=[4, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = lens_model.forward(input_ids=input_ids, attention_mask=attention_mask, targets=target_ids)\n",
    "probs = lens_model.get_probs(input_ids=input_ids, attention_mask=attention_mask, targets=target_ids, target_index=target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0936e-06, 8.1015e-08],\n",
       "         [1.4278e-08, 4.1807e-10],\n",
       "         [8.1728e-13, 6.0328e-10],\n",
       "         ...,\n",
       "         [2.1408e-13, 1.0038e-09],\n",
       "         [3.3702e-09, 8.7198e-09],\n",
       "         [7.5801e-09, 1.0747e-08]],\n",
       "\n",
       "        [[1.6471e-04, 1.4173e-08],\n",
       "         [2.7368e-08, 1.6117e-09],\n",
       "         [5.8699e-12, 3.3553e-09],\n",
       "         ...,\n",
       "         [1.8054e-12, 8.9238e-11],\n",
       "         [3.2829e-09, 3.8163e-08],\n",
       "         [5.5882e-08, 5.0044e-08]],\n",
       "\n",
       "        [[6.4718e-05, 5.9351e-07],\n",
       "         [5.0786e-08, 2.1378e-08],\n",
       "         [4.3852e-13, 7.5696e-07],\n",
       "         ...,\n",
       "         [1.7670e-11, 1.2457e-07],\n",
       "         [3.6081e-06, 3.3918e-10],\n",
       "         [1.1158e-07, 4.1614e-07]],\n",
       "\n",
       "        [[4.9534e-07, 2.5188e-07],\n",
       "         [8.3733e-08, 3.9527e-09],\n",
       "         [4.5760e-11, 1.9581e-08],\n",
       "         ...,\n",
       "         [2.2173e-11, 1.3459e-09],\n",
       "         [2.8648e-09, 1.3291e-10],\n",
       "         [2.1141e-07, 9.3427e-09]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "data, input_ids, target_ids, attention_mask, target_index = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 50257])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids, labels=target_ids, output_hidden_states=True, attention_mask=attention_mask).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = lens_model.forward(input_ids, attention_mask, target_ids)#, target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 64, 50257])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "base_model_logits = torch.stack([base_model_logits for layer in range(2)], dim=1)\n",
    "base_model_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 50257, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = lens_model.forward(input_ids=input_ids, attention_mask=attention_mask, targets=target_ids)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50257, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(logits[torch.arange(logits.shape[0]), target_index-1], dim=-2)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1524e-07, 2.1782e-08],\n",
       "        [6.4313e-06, 9.6567e-09],\n",
       "        [1.0520e-04, 1.7076e-07],\n",
       "        [2.7049e-07, 1.9339e-11]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(probs.shape[0]), target_ids[torch.arange(probs.shape[0]), target_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1524e-07, 2.1782e-08],\n",
       "        [6.4313e-06, 9.6567e-09],\n",
       "        [1.0520e-04, 1.7076e-07],\n",
       "        [2.7049e-07, 1.9339e-11]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model.get_correct_class_probs(input_ids, attention_mask, target_ids, target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.stack([target_ids for layer in range(2)], dim=1)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targs = target_ids[torch.arange(4),target_index]\n",
    "targs.shape\n",
    "targets = torch.stack([targs for layer in range(2)], dim=1)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 50257, 2])\n",
      "tensor(2.0001, grad_fn=<SumBackward0>)\n",
      "tensor([[1.0001, 1.0000],\n",
      "        [1.0001, 1.0000],\n",
      "        [1.0001, 1.0001],\n",
      "        [1.0001, 1.0001]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "probs = lens_model.get_probs(input_ids, attention_mask, target_ids, target_index)\n",
    "print(probs.shape)\n",
    "print(probs[1].sum())\n",
    "print(torch.sum(probs, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-11.9520, -32.1912],\n",
       "          [-19.1287, -24.5467],\n",
       "          [-30.1045, -23.2777],\n",
       "          ...,\n",
       "          [-15.8533, -31.1020],\n",
       "          [-11.6974, -37.6973],\n",
       "          [-14.4931, -24.1138]],\n",
       "\n",
       "         [[ -5.9640, -26.1626],\n",
       "          [ -9.7150, -20.3601],\n",
       "          [-13.1527, -23.9250],\n",
       "          ...,\n",
       "          [-16.0871, -21.4656],\n",
       "          [-14.7223, -25.8494],\n",
       "          [ -7.9957, -25.0632]],\n",
       "\n",
       "         [[ -0.2052, -11.4745],\n",
       "          [ -3.2747,  -5.7795],\n",
       "          [ -7.0115,  -7.3103],\n",
       "          ...,\n",
       "          [-10.6523, -13.7001],\n",
       "          [ -7.0557,  -8.6894],\n",
       "          [ -3.6095,  -6.9114]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  2.4722, -11.7025],\n",
       "          [ -0.4998,  -8.1059],\n",
       "          [-11.4415,  -6.1599],\n",
       "          ...,\n",
       "          [ -5.4269, -10.2061],\n",
       "          [ -3.2803, -13.9883],\n",
       "          [  6.1967, -13.9688]],\n",
       "\n",
       "         [[  2.5067, -11.6910],\n",
       "          [ -0.4917,  -8.1091],\n",
       "          [-11.4312,  -6.1517],\n",
       "          ...,\n",
       "          [ -5.3727, -10.2076],\n",
       "          [ -3.2349, -13.9889],\n",
       "          [  6.2535, -13.9669]],\n",
       "\n",
       "         [[  2.4919, -11.6387],\n",
       "          [ -0.5366,  -8.0761],\n",
       "          [-11.4654,  -6.1026],\n",
       "          ...,\n",
       "          [ -5.3734, -10.1578],\n",
       "          [ -3.2668, -13.9492],\n",
       "          [  6.2510, -13.9300]]],\n",
       "\n",
       "\n",
       "        [[[-11.9540, -32.3865],\n",
       "          [-19.2006, -24.8310],\n",
       "          [-30.1313, -23.6169],\n",
       "          ...,\n",
       "          [-15.8466, -31.1761],\n",
       "          [-11.6441, -37.6877],\n",
       "          [-14.5859, -24.1435]],\n",
       "\n",
       "         [[ -3.1934, -30.1747],\n",
       "          [-10.9591, -25.6106],\n",
       "          [-17.2754, -26.6151],\n",
       "          ...,\n",
       "          [-11.6292, -20.1978],\n",
       "          [-10.0041, -25.9809],\n",
       "          [ -8.5667, -27.0629]],\n",
       "\n",
       "         [[  2.8148, -29.5249],\n",
       "          [ -0.9474, -26.4081],\n",
       "          [ -4.2127, -28.1398],\n",
       "          ...,\n",
       "          [ -6.9870, -32.2000],\n",
       "          [ -2.8228, -25.4201],\n",
       "          [ -1.5166, -27.6266]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -0.6525, -25.2055],\n",
       "          [ -9.3498, -23.3053],\n",
       "          [-11.9553, -26.5538],\n",
       "          ...,\n",
       "          [-11.4022, -21.0754],\n",
       "          [-10.0577, -22.7572],\n",
       "          [  0.3310, -20.9351]],\n",
       "\n",
       "         [[ -0.5955, -25.1840],\n",
       "          [ -9.3253, -23.2994],\n",
       "          [-11.9447, -26.5187],\n",
       "          ...,\n",
       "          [-11.3457, -21.0533],\n",
       "          [ -9.9999, -22.7576],\n",
       "          [  0.4062, -20.9214]],\n",
       "\n",
       "         [[ -0.6754, -25.1518],\n",
       "          [ -9.4136, -23.2743],\n",
       "          [-12.0485, -26.4910],\n",
       "          ...,\n",
       "          [-11.4136, -21.0267],\n",
       "          [-10.0839, -22.7239],\n",
       "          [  0.3542, -20.9012]]],\n",
       "\n",
       "\n",
       "        [[[-11.9131, -31.8044],\n",
       "          [-19.1620, -24.4085],\n",
       "          [-30.1263, -22.9652],\n",
       "          ...,\n",
       "          [-15.7772, -30.7753],\n",
       "          [-11.6607, -37.4777],\n",
       "          [-14.5730, -23.7090]],\n",
       "\n",
       "         [[  0.5132, -20.0203],\n",
       "          [ -7.6070, -17.7178],\n",
       "          [-13.9710, -14.7351],\n",
       "          ...,\n",
       "          [-11.8993, -16.6768],\n",
       "          [ -8.0448, -20.9273],\n",
       "          [ -8.1218, -18.7083]],\n",
       "\n",
       "         [[ -0.3632, -16.9781],\n",
       "          [ -2.4998, -17.1076],\n",
       "          [ -7.8676, -14.5069],\n",
       "          ...,\n",
       "          [-12.1581, -18.6474],\n",
       "          [ -6.5401, -21.3109],\n",
       "          [ -5.0274, -16.2516]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  4.5417,  -0.9815],\n",
       "          [ -4.8052,  -4.1899],\n",
       "          [ -7.1759,   0.9641],\n",
       "          ...,\n",
       "          [-14.7268,  -4.3542],\n",
       "          [ -8.3655,  -9.8989],\n",
       "          [  0.3620,  -1.7345]],\n",
       "\n",
       "         [[  4.6481,  -0.9597],\n",
       "          [ -4.7185,  -4.1929],\n",
       "          [ -7.0971,   0.9874],\n",
       "          ...,\n",
       "          [-14.6055,  -4.3408],\n",
       "          [ -8.2666,  -9.8972],\n",
       "          [  0.4933,  -1.7192]],\n",
       "\n",
       "         [[  4.5755,  -0.9464],\n",
       "          [ -4.8218,  -4.1814],\n",
       "          [ -7.1723,   0.9987],\n",
       "          ...,\n",
       "          [-14.6616,  -4.3056],\n",
       "          [ -8.3532,  -9.8854],\n",
       "          [  0.4388,  -1.7161]]],\n",
       "\n",
       "\n",
       "        [[[-11.9674, -31.9841],\n",
       "          [-19.1610, -24.6186],\n",
       "          [-30.1175, -23.2936],\n",
       "          ...,\n",
       "          [-15.7844, -31.0514],\n",
       "          [-11.6559, -37.6199],\n",
       "          [-14.5616, -24.0965]],\n",
       "\n",
       "         [[ -3.4742, -12.9884],\n",
       "          [ -8.8807, -14.0265],\n",
       "          [-14.4323, -13.6488],\n",
       "          ...,\n",
       "          [-12.5015, -16.2829],\n",
       "          [-11.4379, -17.0160],\n",
       "          [ -8.8577, -15.8629]],\n",
       "\n",
       "         [[  0.2087, -16.5433],\n",
       "          [ -2.3410, -17.1954],\n",
       "          [ -6.6983, -17.9889],\n",
       "          ...,\n",
       "          [-10.3839, -25.5679],\n",
       "          [ -6.6705, -22.8039],\n",
       "          [ -3.2364, -19.2879]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  0.7876,  -6.7510],\n",
       "          [ -6.3185, -13.2576],\n",
       "          [ -9.5837, -10.7414],\n",
       "          ...,\n",
       "          [ -1.8694, -14.1988],\n",
       "          [ -2.6519, -12.4795],\n",
       "          [ -0.3421, -13.6969]],\n",
       "\n",
       "         [[  0.8915,  -6.7412],\n",
       "          [ -6.2394, -13.2592],\n",
       "          [ -9.5197, -10.7080],\n",
       "          ...,\n",
       "          [ -1.7533, -14.1776],\n",
       "          [ -2.5758, -12.4895],\n",
       "          [ -0.2234, -13.6795]],\n",
       "\n",
       "         [[  0.8238,  -6.6866],\n",
       "          [ -6.3427, -13.2299],\n",
       "          [ -9.6242, -10.6492],\n",
       "          ...,\n",
       "          [ -1.7872, -14.1182],\n",
       "          [ -2.6366, -12.4385],\n",
       "          [ -0.2797, -13.6301]]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model.forward(input_ids, attention_mask, target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 50257])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids, labels=target_ids, output_hidden_states=True, attention_mask=attention_mask).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_ = target_ids[torch.arange(4), target_index]\n",
    "targets_ = torch.stack([targets_ for layer in range(2)], dim=1)\n",
    "targets_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50257, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model.get_probs(input_ids, attention_mask, target_ids, target_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "layers = []\n",
    "for layer in range(12):\n",
    "    nl = Linear_lens.from_model(model)\n",
    "    nl.set_parameters({'weight': torch.nn.Parameter(torch.eye(model.config.hidden_size)),\\\n",
    "                        'bias': torch.nn.Parameter(torch.zeros(model.config.hidden_size))})\n",
    "    lens.append(nl)\n",
    "    layers.append(layer)\n",
    "\n",
    "lens_model = Lens_model(lens, layers, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/dataset_test.pkl\", \"rb\") as f:\n",
    "    dataset_test = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/dataset_train.pkl\", \"rb\") as f:\n",
    "    dataset_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = DataLoader(dataset_train, batch_size=4, shuffle=False)\n",
    "data_test = DataLoader(dataset_test, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, input_ids, target_ids, attention_mask, target_index = next(iter(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  16.0838,    6.2038,   -3.5437,  ...,   -6.7148,   -7.2858,\n",
       "             -8.2691],\n",
       "          [  21.1776,    6.2868,   -3.5077,  ...,   -6.6434,   -7.1885,\n",
       "             -8.1944],\n",
       "          [  19.7677,    4.9822,   -5.9960,  ...,   -8.7432,   -9.4221,\n",
       "            -10.4845],\n",
       "          ...,\n",
       "          [  11.1786,   -4.1631,  -11.4905,  ...,  -13.0316,  -13.7163,\n",
       "            -14.8179],\n",
       "          [  13.6240,   -2.5583,  -11.0643,  ...,  -12.2197,  -12.7285,\n",
       "            -13.5820],\n",
       "          [  20.5195,    5.9294,   -3.4365,  ...,   -6.2053,   -6.7674,\n",
       "             -7.7027]],\n",
       "\n",
       "         [[  16.8238,   -8.5267,   -5.0287,  ...,  -71.0284,  -66.2512,\n",
       "            -83.1334],\n",
       "          [  20.4722,   -6.7212,   -3.0400,  ...,  -69.7362,  -63.2890,\n",
       "            -79.7683],\n",
       "          [  22.3595,   -6.9423,   -2.4522,  ...,  -64.7502,  -64.7687,\n",
       "            -84.7910],\n",
       "          ...,\n",
       "          [  22.3544,  -15.8880,  -16.4908,  ...,  -92.0121,  -90.2242,\n",
       "           -104.7963],\n",
       "          [  17.1161,  -13.3273,  -13.2965,  ...,  -85.2986,  -80.7180,\n",
       "            -95.6397],\n",
       "          [  15.7326,   -9.0100,   -5.6064,  ...,  -64.7307,  -61.9305,\n",
       "            -77.0013]],\n",
       "\n",
       "         [[  34.9939,   -6.3608,   -6.2144,  ...,  -64.9087,  -60.7549,\n",
       "            -63.9050],\n",
       "          [  37.8606,   -4.9771,   -5.5866,  ...,  -61.7768,  -57.1388,\n",
       "            -60.8989],\n",
       "          [  33.3534,   -8.4286,   -9.8809,  ...,  -60.2092,  -60.7631,\n",
       "            -67.0714],\n",
       "          ...,\n",
       "          [  39.2036,  -19.6824,  -20.5802,  ...,  -84.3804,  -80.8489,\n",
       "            -78.9678],\n",
       "          [  29.3637,  -20.8892,  -22.3353,  ...,  -81.0184,  -75.7773,\n",
       "            -74.4544],\n",
       "          [  31.2646,   -9.5616,   -9.3731,  ...,  -57.7038,  -54.3079,\n",
       "            -56.8862]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  58.3495,  -15.5341,  -12.8716,  ...,  -67.7758,  -81.4725,\n",
       "           -108.3916],\n",
       "          [  48.5592,   -9.7583,   -9.0729,  ...,  -65.6617,  -77.5427,\n",
       "           -104.6920],\n",
       "          [  49.7401,  -13.1482,  -10.6138,  ...,  -61.2916,  -80.3263,\n",
       "           -110.0464],\n",
       "          ...,\n",
       "          [  53.5119,  -29.5817,  -30.5332,  ...,  -88.6654, -104.0048,\n",
       "           -130.4778],\n",
       "          [  62.6094,  -26.3646,  -25.7854,  ...,  -76.9752,  -89.0539,\n",
       "           -114.0849],\n",
       "          [ 102.0932,   -3.2042,   -4.4254,  ...,  -59.6622,  -75.4387,\n",
       "           -101.6684]],\n",
       "\n",
       "         [[  57.9917,  -15.6029,  -12.9185,  ...,  -67.8030,  -81.4920,\n",
       "           -108.4165],\n",
       "          [  48.0478,   -9.8195,   -9.1302,  ...,  -65.6959,  -77.5697,\n",
       "           -104.7231],\n",
       "          [  49.2444,  -13.2232,  -10.6881,  ...,  -61.3366,  -80.3625,\n",
       "           -110.0844],\n",
       "          ...,\n",
       "          [  53.0683,  -29.6287,  -30.5766,  ...,  -88.6932, -104.0283,\n",
       "           -130.5081],\n",
       "          [  62.2273,  -26.4645,  -25.8640,  ...,  -77.0136,  -89.0823,\n",
       "           -114.1184],\n",
       "          [ 101.7887,   -3.2632,   -4.4811,  ...,  -59.6955,  -75.4656,\n",
       "           -101.6983]],\n",
       "\n",
       "         [[  57.2229,  -15.6126,  -12.9283,  ...,  -67.7932,  -81.5296,\n",
       "           -108.4971],\n",
       "          [  47.4529,   -9.8292,   -9.1442,  ...,  -65.6874,  -77.6042,\n",
       "           -104.8004],\n",
       "          [  48.5970,  -13.2449,  -10.7129,  ...,  -61.3284,  -80.3978,\n",
       "           -110.1580],\n",
       "          ...,\n",
       "          [  52.4887,  -29.6776,  -30.6158,  ...,  -88.6989, -104.0764,\n",
       "           -130.5988],\n",
       "          [  61.4448,  -26.4567,  -25.8547,  ...,  -77.0040,  -89.1242,\n",
       "           -114.2047],\n",
       "          [ 101.3055,   -3.2285,   -4.4726,  ...,  -59.6867,  -75.5022,\n",
       "           -101.7789]]],\n",
       "\n",
       "\n",
       "        [[[  16.0838,    6.8182,   -3.4644,  ...,   -6.0405,   -6.2813,\n",
       "             -7.2003],\n",
       "          [  21.1776,    7.6821,   -3.1773,  ...,   -6.1865,   -6.3067,\n",
       "             -7.2352],\n",
       "          [  19.7677,    6.4664,   -5.6643,  ...,   -8.1612,   -8.3641,\n",
       "             -9.3246],\n",
       "          ...,\n",
       "          [  11.1786,   -2.0111,  -10.7308,  ...,  -12.4735,  -12.8357,\n",
       "            -14.0993],\n",
       "          [  13.6240,   -0.6532,  -10.4918,  ...,  -11.9324,  -12.3269,\n",
       "            -13.3982],\n",
       "          [  20.5195,    7.2137,   -3.1781,  ...,   -5.9413,   -6.1153,\n",
       "             -7.0031]],\n",
       "\n",
       "         [[  16.8238,   -9.7695,   -7.1772,  ...,  -30.6271,  -31.2854,\n",
       "            -48.4104],\n",
       "          [  20.4722,   -7.3156,   -4.5685,  ...,  -37.0506,  -34.6091,\n",
       "            -49.3967],\n",
       "          [  22.3595,   -7.3201,   -3.6509,  ...,  -28.4300,  -31.6442,\n",
       "            -52.5506],\n",
       "          ...,\n",
       "          [  22.3544,  -15.3935,  -15.9559,  ...,  -56.9392,  -52.7491,\n",
       "            -72.5440],\n",
       "          [  17.1161,  -14.5056,  -13.6957,  ...,  -44.3703,  -46.8502,\n",
       "            -65.5143],\n",
       "          [  15.7326,  -10.6332,   -8.5273,  ...,  -38.5136,  -35.5108,\n",
       "            -49.9911]],\n",
       "\n",
       "         [[  34.9939,   -7.1738,   -8.8627,  ...,  -26.1047,  -33.2255,\n",
       "            -51.7140],\n",
       "          [  37.8606,   -5.3801,   -7.6187,  ...,  -31.5402,  -37.0991,\n",
       "            -53.8430],\n",
       "          [  33.3534,   -8.9579,  -12.7735,  ...,  -30.2165,  -36.7914,\n",
       "            -58.1918],\n",
       "          ...,\n",
       "          [  39.2036,  -19.7351,  -21.8168,  ...,  -50.7560,  -52.5689,\n",
       "            -69.1192],\n",
       "          [  29.3637,  -21.2228,  -24.0096,  ...,  -47.9241,  -51.8647,\n",
       "            -68.0166],\n",
       "          [  31.2646,  -10.8173,  -12.5874,  ...,  -31.7073,  -34.6075,\n",
       "            -51.2487]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  58.3495,  -21.0535,  -25.8584,  ...,  -38.0174,  -30.2505,\n",
       "            -66.4794],\n",
       "          [  48.5592,  -14.8226,  -19.7767,  ...,  -42.5428,  -31.2368,\n",
       "            -65.5180],\n",
       "          [  49.7401,  -16.1988,  -21.9565,  ...,  -33.5428,  -29.3753,\n",
       "            -68.3108],\n",
       "          ...,\n",
       "          [  53.5119,  -32.8804,  -36.9065,  ...,  -66.5066,  -58.0795,\n",
       "            -94.7722],\n",
       "          [  62.6094,  -30.9371,  -37.8641,  ...,  -57.2719,  -51.8525,\n",
       "            -87.7988],\n",
       "          [ 102.0932,   -8.7781,  -18.5471,  ...,  -40.6302,  -32.8414,\n",
       "            -66.0720]],\n",
       "\n",
       "         [[  57.9917,  -21.1441,  -25.9051,  ...,  -38.0143,  -30.2176,\n",
       "            -66.3759],\n",
       "          [  48.0478,  -14.9050,  -19.8169,  ...,  -42.5462,  -31.2082,\n",
       "            -65.4191],\n",
       "          [  49.2444,  -16.2997,  -22.0051,  ...,  -33.5439,  -29.3408,\n",
       "            -68.2084],\n",
       "          ...,\n",
       "          [  53.0683,  -32.9669,  -36.9399,  ...,  -66.5189,  -58.0526,\n",
       "            -94.6738],\n",
       "          [  62.2273,  -31.0657,  -37.9239,  ...,  -57.2883,  -51.8301,\n",
       "            -87.7038],\n",
       "          [ 101.7887,   -8.8515,  -18.5906,  ...,  -40.6393,  -32.8188,\n",
       "            -65.9807]],\n",
       "\n",
       "         [[  57.2229,  -21.2275,  -25.9139,  ...,  -38.0258,  -30.2508,\n",
       "            -66.4442],\n",
       "          [  47.4529,  -15.0090,  -19.8427,  ...,  -42.5380,  -31.2244,\n",
       "            -65.4723],\n",
       "          [  48.5970,  -16.4077,  -22.0374,  ...,  -33.5530,  -29.3671,\n",
       "            -68.2686],\n",
       "          ...,\n",
       "          [  52.4887,  -33.0803,  -36.9826,  ...,  -66.5288,  -58.0894,\n",
       "            -94.7459],\n",
       "          [  61.4448,  -31.1407,  -37.9322,  ...,  -57.2883,  -51.8620,\n",
       "            -87.7741],\n",
       "          [ 101.3055,   -8.8844,  -18.5836,  ...,  -40.6374,  -32.8433,\n",
       "            -66.0438]]],\n",
       "\n",
       "\n",
       "        [[[  16.0838,    5.9253,   -3.5597,  ...,   -6.3587,   -7.0612,\n",
       "             -8.5966],\n",
       "          [  21.1776,    5.9955,   -3.5085,  ...,   -6.2098,   -6.7804,\n",
       "             -8.0901],\n",
       "          [  19.7677,    3.9557,   -6.2028,  ...,   -8.3808,   -9.0250,\n",
       "            -10.4032],\n",
       "          ...,\n",
       "          [  11.1786,   -4.2904,  -11.0970,  ...,  -12.2358,  -12.8619,\n",
       "            -14.3357],\n",
       "          [  13.6240,   -1.5146,  -10.5363,  ...,  -11.9691,  -12.6680,\n",
       "            -14.1372],\n",
       "          [  20.5195,    5.3767,   -3.4942,  ...,   -5.9669,   -6.5649,\n",
       "             -7.8914]],\n",
       "\n",
       "         [[  16.8238,   -7.8487,   -7.0281,  ...,  -32.5915,  -40.4198,\n",
       "            -57.6220],\n",
       "          [  20.4722,   -5.4031,   -4.5786,  ...,  -28.8908,  -32.1252,\n",
       "            -46.1582],\n",
       "          [  22.3595,   -6.5040,   -4.7534,  ...,  -27.2598,  -34.7751,\n",
       "            -53.8951],\n",
       "          ...,\n",
       "          [  22.3544,  -14.5979,  -17.7409,  ...,  -44.3741,  -49.7797,\n",
       "            -65.4131],\n",
       "          [  17.1161,  -12.2222,  -12.7240,  ...,  -41.1728,  -49.5852,\n",
       "            -63.8360],\n",
       "          [  15.7326,   -7.8590,   -7.4810,  ...,  -31.0805,  -36.8693,\n",
       "            -52.1525]],\n",
       "\n",
       "         [[  34.9939,   -6.6028,   -7.4873,  ...,  -34.7700,  -41.0165,\n",
       "            -56.5699],\n",
       "          [  37.8606,   -4.6244,   -6.7221,  ...,  -32.3077,  -36.1281,\n",
       "            -47.3868],\n",
       "          [  33.3534,   -8.3514,  -11.4903,  ...,  -32.1959,  -38.7911,\n",
       "            -54.6862],\n",
       "          ...,\n",
       "          [  39.2036,  -21.0021,  -23.1181,  ...,  -49.4996,  -51.9678,\n",
       "            -63.4821],\n",
       "          [  29.3637,  -20.5952,  -22.5177,  ...,  -47.8689,  -53.2629,\n",
       "            -64.4415],\n",
       "          [  31.2646,  -10.0860,  -11.8479,  ...,  -34.1846,  -36.9901,\n",
       "            -50.8174]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  58.3495,  -14.4524,  -13.7815,  ...,  -35.2165,  -43.9068,\n",
       "            -55.0087],\n",
       "          [  48.5592,  -12.1486,  -13.3138,  ...,  -34.2601,  -39.7564,\n",
       "            -48.1200],\n",
       "          [  49.7401,  -14.6268,  -15.4634,  ...,  -31.6726,  -41.3423,\n",
       "            -51.9348],\n",
       "          ...,\n",
       "          [  53.5119,  -25.8827,  -28.6200,  ...,  -46.4054,  -52.1035,\n",
       "            -60.3121],\n",
       "          [  62.6094,  -24.5493,  -23.3342,  ...,  -46.0683,  -54.1478,\n",
       "            -61.8968],\n",
       "          [ 102.0932,   -5.6907,   -8.0027,  ...,  -30.8459,  -38.9003,\n",
       "            -47.8068]],\n",
       "\n",
       "         [[  57.9917,  -14.4840,  -13.7975,  ...,  -35.2404,  -43.9200,\n",
       "            -55.0119],\n",
       "          [  48.0478,  -12.1871,  -13.3340,  ...,  -34.2869,  -39.7749,\n",
       "            -48.1267],\n",
       "          [  49.2444,  -14.6418,  -15.4942,  ...,  -31.7063,  -41.3620,\n",
       "            -51.9408],\n",
       "          ...,\n",
       "          [  53.0683,  -25.8703,  -28.6164,  ...,  -46.4267,  -52.1172,\n",
       "            -60.3170],\n",
       "          [  62.2273,  -24.5855,  -23.3454,  ...,  -46.1061,  -54.1755,\n",
       "            -61.9112],\n",
       "          [ 101.7887,   -5.7002,   -8.0119,  ...,  -30.8810,  -38.9247,\n",
       "            -47.8179]],\n",
       "\n",
       "         [[  57.2229,  -14.5870,  -13.8322,  ...,  -35.2210,  -43.9032,\n",
       "            -55.0006],\n",
       "          [  47.4529,  -12.2828,  -13.3650,  ...,  -34.2668,  -39.7589,\n",
       "            -48.1160],\n",
       "          [  48.5970,  -14.7640,  -15.5317,  ...,  -31.6865,  -41.3463,\n",
       "            -51.9294],\n",
       "          ...,\n",
       "          [  52.4887,  -26.0099,  -28.6745,  ...,  -46.4066,  -52.1020,\n",
       "            -60.3077],\n",
       "          [  61.4448,  -24.6911,  -23.3790,  ...,  -46.0804,  -54.1548,\n",
       "            -61.8986],\n",
       "          [ 101.3055,   -5.7709,   -8.0396,  ...,  -30.8562,  -38.9019,\n",
       "            -47.8029]]],\n",
       "\n",
       "\n",
       "        [[[  16.0838,    4.3407,   -3.7124,  ...,   -6.3650,   -6.6979,\n",
       "             -7.9818],\n",
       "          [  21.1776,    4.3078,   -3.6465,  ...,   -6.3007,   -6.5393,\n",
       "             -7.6923],\n",
       "          [  19.7677,    1.7724,   -6.2167,  ...,   -8.6380,   -8.9625,\n",
       "            -10.2241],\n",
       "          ...,\n",
       "          [  11.1786,   -5.6547,  -11.3336,  ...,  -12.4195,  -12.5974,\n",
       "            -13.8718],\n",
       "          [  13.6240,   -4.5655,  -10.8647,  ...,  -12.0270,  -12.2533,\n",
       "            -13.4627],\n",
       "          [  20.5195,    3.0984,   -3.7154,  ...,   -6.0958,   -6.2730,\n",
       "             -7.3501]],\n",
       "\n",
       "         [[  16.8238,  -12.5156,   -9.7549,  ...,  -22.6498,  -25.2995,\n",
       "            -58.5385],\n",
       "          [  20.4722,   -9.1222,   -7.0337,  ...,  -20.4301,  -21.8666,\n",
       "            -52.7666],\n",
       "          [  22.3595,  -10.3869,   -6.4481,  ...,  -17.5385,  -19.4425,\n",
       "            -55.5427],\n",
       "          ...,\n",
       "          [  22.3544,  -17.8215,  -20.2938,  ...,  -31.4543,  -31.6701,\n",
       "            -65.0924],\n",
       "          [  17.1161,  -17.7141,  -16.8184,  ...,  -26.2013,  -27.4173,\n",
       "            -60.7280],\n",
       "          [  15.7326,  -13.8428,  -11.0695,  ...,  -21.6671,  -22.3348,\n",
       "            -52.4072]],\n",
       "\n",
       "         [[  34.9939,   -6.5784,   -7.6652,  ...,  -30.1119,  -34.4049,\n",
       "            -56.2809],\n",
       "          [  37.8606,   -4.1372,   -6.7427,  ...,  -30.8788,  -32.9997,\n",
       "            -52.0981],\n",
       "          [  33.3534,   -8.4532,  -12.0108,  ...,  -31.8881,  -33.8972,\n",
       "            -57.0000],\n",
       "          ...,\n",
       "          [  39.2036,  -19.1163,  -21.7153,  ...,  -42.7435,  -42.2766,\n",
       "            -60.8856],\n",
       "          [  29.3637,  -21.1623,  -23.0995,  ...,  -44.4614,  -41.9109,\n",
       "            -62.2552],\n",
       "          [  31.2646,  -10.4832,  -11.6667,  ...,  -32.1954,  -31.8242,\n",
       "            -51.8963]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  58.3495,  -18.4420,  -21.6924,  ...,  -43.9273,  -40.7330,\n",
       "            -53.4235],\n",
       "          [  48.5592,  -15.1727,  -19.4741,  ...,  -41.5983,  -35.9092,\n",
       "            -47.4686],\n",
       "          [  49.7401,  -19.6375,  -22.6060,  ...,  -43.7617,  -40.0333,\n",
       "            -54.5232],\n",
       "          ...,\n",
       "          [  53.5119,  -33.7107,  -39.7337,  ...,  -56.1838,  -48.6364,\n",
       "            -61.1646],\n",
       "          [  62.6094,  -30.6399,  -34.2876,  ...,  -55.5863,  -47.1547,\n",
       "            -59.4835],\n",
       "          [ 102.0932,  -12.2396,  -17.9845,  ...,  -42.1225,  -35.3841,\n",
       "            -46.6243]],\n",
       "\n",
       "         [[  57.9917,  -18.4788,  -21.7582,  ...,  -43.9582,  -40.7507,\n",
       "            -53.4400],\n",
       "          [  48.0478,  -15.1884,  -19.5238,  ...,  -41.6191,  -35.9187,\n",
       "            -47.4802],\n",
       "          [  49.2444,  -19.6692,  -22.6766,  ...,  -43.7831,  -40.0419,\n",
       "            -54.5330],\n",
       "          ...,\n",
       "          [  53.0683,  -33.7421,  -39.8009,  ...,  -56.2169,  -48.6571,\n",
       "            -61.1838],\n",
       "          [  62.2273,  -30.6940,  -34.3620,  ...,  -55.6109,  -47.1701,\n",
       "            -59.5010],\n",
       "          [ 101.7887,  -12.2531,  -18.0274,  ...,  -42.1410,  -35.3937,\n",
       "            -46.6354]],\n",
       "\n",
       "         [[  57.2229,  -18.5103,  -21.7159,  ...,  -43.9463,  -40.7530,\n",
       "            -53.4486],\n",
       "          [  47.4529,  -15.1957,  -19.4779,  ...,  -41.6011,  -35.9132,\n",
       "            -47.4824],\n",
       "          [  48.5970,  -19.6633,  -22.5974,  ...,  -43.7617,  -40.0343,\n",
       "            -54.5343],\n",
       "          ...,\n",
       "          [  52.4887,  -33.7952,  -39.7736,  ...,  -56.2117,  -48.6625,\n",
       "            -61.1950],\n",
       "          [  61.4448,  -30.7023,  -34.3046,  ...,  -55.6023,  -47.1745,\n",
       "            -59.5133],\n",
       "          [ 101.3055,  -12.2018,  -17.9563,  ...,  -42.1356,  -35.4002,\n",
       "            -46.6469]]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model.forward(input_ids, attention_mask, target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lens_model(\n",
       "  (model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (lens): ParameterList(\n",
       "      (0): Object of type: Linear_lens\n",
       "      (1): Object of type: Linear_lens\n",
       "      (2): Object of type: Linear_lens\n",
       "      (3): Object of type: Linear_lens\n",
       "      (4): Object of type: Linear_lens\n",
       "      (5): Object of type: Linear_lens\n",
       "      (6): Object of type: Linear_lens\n",
       "      (7): Object of type: Linear_lens\n",
       "      (8): Object of type: Linear_lens\n",
       "      (9): Object of type: Linear_lens\n",
       "      (10): Object of type: Linear_lens\n",
       "      (11): Object of type: Linear_lens\n",
       "    (0): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (1): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (2): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (3): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (4): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (5): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (6): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (7): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (8): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (9): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (10): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (11): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (unembed): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Linear_lens(\n",
       "  (linear): Linear(in_features=10, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_ = Linear_lens(10, 10)\n",
    "lens_.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lens_model, './models/lens_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/lens_model_cpu.pkl', \"rb\") as f:\n",
    "    lens_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "    Batch: 0/1857, Loss: 0.2536962330341339\n",
      "Average loss: 1.2568920128563843\n",
      "[0.2536962330341339, 2.8589835166931152, 2.081822156906128, 0.4752136468887329, 1.0852179527282715, 0.5857743620872498, 0.08212531358003616, 0.3433285653591156, 1.0946650505065918, 0.3625377118587494, 0.1785324066877365, 0.6376705765724182, 1.1370208263397217, 0.6946799159049988, 4.588211536407471, 1.0307098627090454, 0.5813913345336914, 0.6113443374633789, 2.0838139057159424, 1.7911590337753296, 0.8209935426712036, 0.4804232120513916, 0.38315457105636597, 0.6116137504577637, 0.809879720211029, 0.7492644190788269, 0.8996995687484741, 2.0654397010803223, 0.20470036566257477, 4.281492710113525, 0.18094244599342346, 0.40408843755722046, 0.20104187726974487, 0.7827140688896179, 0.24521024525165558, 0.2908748388290405, 5.148050308227539, 0.7815617322921753, 0.8796820044517517, 0.790023922920227, 0.35296887159347534, 0.7179099917411804, 1.2749625444412231, 1.2891569137573242, 0.08150981366634369, 0.9785296320915222, 1.116032361984253, 1.842317819595337, 0.11127915233373642, 1.917852759361267, 1.5210216045379639, 1.4103878736495972, 2.7996184825897217, 3.5764195919036865, 2.3366472721099854, 2.932798147201538, 0.5684186220169067, 0.3705068826675415, 4.384732723236084, 0.6939609050750732, 1.2932265996932983, 0.4012260437011719, 0.10376052558422089, 0.9569133520126343, 0.3980253040790558, 0.7641780376434326, 0.26746731996536255, 2.8207578659057617, 2.498945713043213, 0.9479315876960754, 0.5989089012145996, 3.839679718017578, 1.318869709968567, 0.36748695373535156, 0.23754748702049255, 6.795914173126221, 2.4385108947753906, 1.318945050239563, 1.363110065460205, 0.6174402236938477, 0.08106204122304916, 1.0050837993621826, 0.5182181000709534, 0.0970839411020279, 2.607957363128662, 0.2615348696708679, 0.7913809418678284, 0.19914431869983673, 3.1671512126922607, 0.799338698387146, 0.10241585969924927, 0.5750187039375305, 0.6040759086608887, 0.27767857909202576, 0.49930691719055176, 2.8472900390625, 0.10861867666244507, 1.9805989265441895, 0.3643002510070801, 0.9841911196708679, 5.880015850067139]\n",
      "1.2568920128563843\n"
     ]
    }
   ],
   "source": [
    "dataset_test_path = \"datasets/dataset_test.pkl\"\n",
    "output_path = \"output\"\n",
    "device = \"cpu\"\n",
    "batch_size = 4\n",
    "max_length = 64\n",
    "loss_function_name = \"kl\"\n",
    "losses_valid_t, average_loss_valid = validate(lens_model, model, dataset_test_path, max_length, device, output_path, batch_size, loss_function_name)\n",
    "print(losses_valid_t)\n",
    "print(average_loss_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "layers = []\n",
    "for layer in range(12):\n",
    "    nl = Logit_lens.from_model(model)\n",
    "    lens.append(nl)\n",
    "    layers.append(layer)\n",
    "\n",
    "lens_model_l = Lens_model(lens, layers, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "layers = []\n",
    "for layer in range(12):\n",
    "    nl = Linear_lens.from_model(model)\n",
    "    nl.set_parameters({'weight': torch.nn.Parameter(torch.eye(model.config.hidden_size)),\\\n",
    "                        'bias': torch.nn.Parameter(torch.zeros(model.config.hidden_size))})\n",
    "    lens.append(nl)\n",
    "    layers.append(layer)\n",
    "\n",
    "lens_model = Lens_model(lens, layers, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model_l.forward(input_ids, attention_mask, target_ids) == lens_model.forward(input_ids, attention_mask, target_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
