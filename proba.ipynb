{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerko/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import datasets\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembed = model.get_output_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 694.0030, 2338.6108, 1067.6279,  ..., 1493.1703, 1461.0746,\n",
       "         456.2899], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unembed.forward(torch.tensor([float(i) for i in range(768)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.7654,  6.5866,  1.7553,  ...,  9.5762, 15.3242,  6.8427],\n",
       "       grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_layer_norm = model.base_model.ln_f\n",
    "unembed.forward(final_layer_norm.forward(torch.tensor([float(i) for i in range(768)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_2_dataset import GPT2Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "with open(\"datasets/dataset_test.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "data, input_ids, target_ids, attention_mask, target_index = next(iter(dataloader))\n",
    "#attention_mask[0][:target_index] = 1\n",
    "#print(data[0])\n",
    "#print(input_ids[0])\n",
    "#print(target_ids[0])\n",
    "#print(attention_mask[0])\n",
    "model.eval()\n",
    "output = model(input_ids, labels=target_ids, output_hidden_states=True, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is  tensor(3.8217, grad_fn=<NegBackward0>)\n",
      "predicted loss is  tensor(3.8217, grad_fn=<NllLossBackward0>)\n",
      "probabilities are  tensor([0.0720, 0.0393, 0.1288, 0.0006], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"loss is \", -torch.log(torch.softmax(output.logits[torch.arange(output.logits.shape[0]), target_index-1], dim=-1)[torch.arange(output.logits.shape[0]), target_ids[torch.arange(output.logits.shape[0]), target_index]]).mean())\n",
    "print(\"predicted loss is \", output.loss)\n",
    "print(\"probabilities are \", torch.softmax(output.logits[torch.arange(output.logits.shape[0]), target_index-1], dim=-1)[torch.arange(output.logits.shape[0]), target_ids[torch.arange(output.logits.shape[0]), target_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 13, 64, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = output.hidden_states\n",
    "hidden_states[-1].shape\n",
    "hs = torch.stack(hidden_states, dim = 1)\n",
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = unembed.forward(hs)\n",
    "logits_ = unembed.forward(final_layer_norm.forward(hs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 13, 64, 50257])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0720, 0.0393, 0.1288, 0.0006], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(logits[torch.arange(output.logits.shape[0]), -1, target_index-1], dim=-1)[torch.arange(output.logits.shape[0]), target_ids[torch.arange(output.logits.shape[0]), target_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is  tensor(3.8217, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"loss is \", -torch.log(torch.softmax(logits[torch.arange(output.logits.shape[0]), -1, target_index-1], dim=-1)[torch.arange(output.logits.shape[0]), target_ids[torch.arange(output.logits.shape[0]), target_index]]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tuned_lens.nn.lenses import TunedLens, LogitLens\n",
    "from tuned_lens.plotting import PredictionTrajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lens_model import Lens_model\n",
    "from lens import Lens, Logit_lens, Linear_lens\n",
    "\n",
    "lens_4 = Linear_lens.from_model(model)\n",
    "lens_8 = Linear_lens.from_model(model)\n",
    "lens_model = Lens_model([lens_4, lens_8], layers=[4, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = lens_model.forward(input_ids=input_ids, attention_mask=attention_mask, targets=target_ids)\n",
    "probs = lens_model.get_probs(input_ids=input_ids, attention_mask=attention_mask, targets=target_ids, target_index=target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.5031e-08, 6.4239e-10],\n",
       "         [9.7787e-06, 4.0750e-09],\n",
       "         [4.1373e-08, 1.5405e-10],\n",
       "         ...,\n",
       "         [1.5466e-13, 2.7777e-11],\n",
       "         [7.3198e-10, 4.0914e-13],\n",
       "         [2.7261e-09, 1.4884e-11]],\n",
       "\n",
       "        [[4.5172e-10, 9.5926e-10],\n",
       "         [1.2042e-05, 9.8153e-09],\n",
       "         [1.5876e-08, 6.1077e-10],\n",
       "         ...,\n",
       "         [8.0898e-14, 3.2625e-13],\n",
       "         [1.4657e-09, 2.4526e-11],\n",
       "         [7.2036e-11, 1.4454e-08]],\n",
       "\n",
       "        [[4.4109e-09, 1.1394e-08],\n",
       "         [1.2270e-06, 1.8960e-07],\n",
       "         [9.0117e-08, 8.6830e-08],\n",
       "         ...,\n",
       "         [1.2630e-13, 4.7863e-12],\n",
       "         [3.9226e-12, 2.8383e-11],\n",
       "         [5.1628e-09, 1.2626e-08]],\n",
       "\n",
       "        [[2.3229e-09, 6.3803e-09],\n",
       "         [4.3377e-06, 1.0159e-09],\n",
       "         [5.7620e-08, 2.6259e-08],\n",
       "         ...,\n",
       "         [1.8516e-14, 1.8716e-13],\n",
       "         [1.9330e-11, 1.7841e-12],\n",
       "         [3.6748e-12, 7.8151e-09]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "data, input_ids, target_ids, attention_mask, target_index = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 50257])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids, labels=target_ids, output_hidden_states=True, attention_mask=attention_mask).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = lens_model.forward(input_ids, attention_mask, target_ids)#, target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 64, 50257])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "base_model_logits = torch.stack([base_model_logits for layer in range(2)], dim=1)\n",
    "base_model_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 50257, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = lens_model.forward(input_ids=input_ids, attention_mask=attention_mask, targets=target_ids)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50257, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(logits[torch.arange(logits.shape[0]), target_index-1], dim=-2)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6690e-09, 2.5571e-13],\n",
       "        [3.6697e-08, 2.2381e-07],\n",
       "        [7.8043e-10, 1.8521e-08],\n",
       "        [1.6750e-10, 4.3311e-11]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[torch.arange(probs.shape[0]), target_ids[torch.arange(probs.shape[0]), target_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6690e-09, 2.5571e-13],\n",
       "        [3.6697e-08, 2.2381e-07],\n",
       "        [7.8043e-10, 1.8521e-08],\n",
       "        [1.6750e-10, 4.3311e-11]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model.get_correct_class_probs(input_ids, attention_mask, target_ids, target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.stack([target_ids for layer in range(2)], dim=1)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targs = target_ids[torch.arange(4),target_index]\n",
    "targs.shape\n",
    "targets = torch.stack([targs for layer in range(2)], dim=1)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 50257, 2])\n",
      "tensor(2.0001)\n",
      "tensor([[1.0001, 1.0000],\n",
      "        [1.0001, 1.0000],\n",
      "        [1.0000, 1.0001],\n",
      "        [1.0001, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "probs = lens_model.get_probs(input_ids, attention_mask, target_ids, target_index)\n",
    "print(probs.shape)\n",
    "print(probs[1].sum())\n",
    "print(torch.sum(probs, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.6717e+01, -5.4999e+00],\n",
       "          [-1.5374e+01, -9.9038e+00],\n",
       "          [-1.4408e+01, -1.2333e+01],\n",
       "          ...,\n",
       "          [-2.6538e+01, -3.3264e+01],\n",
       "          [-2.2979e+01, -1.4161e+01],\n",
       "          [-1.4656e+01, -1.1132e+01]],\n",
       "\n",
       "         [[ 6.2960e+00, -7.1018e+00],\n",
       "          [ 8.0610e+00, -5.0475e+00],\n",
       "          [ 4.8768e+00, -6.7406e+00],\n",
       "          ...,\n",
       "          [-1.0472e+01, -1.3002e+01],\n",
       "          [ 8.6033e-02, -1.2471e+01],\n",
       "          [ 6.5639e+00, -6.8861e+00]],\n",
       "\n",
       "         [[ 2.2587e+00,  2.4926e-01],\n",
       "          [ 9.2178e+00,  6.2326e+00],\n",
       "          [-7.4384e-01,  1.8114e+00],\n",
       "          ...,\n",
       "          [-6.8657e+00,  3.8178e+00],\n",
       "          [-5.6461e-01, -6.1559e+00],\n",
       "          [-6.1885e-01, -2.7406e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.0819e+00, -7.7930e+00],\n",
       "          [-5.1625e+00, -1.1777e+00],\n",
       "          [-6.7861e+00, -4.8100e+00],\n",
       "          ...,\n",
       "          [-2.3850e+01, -1.0207e+01],\n",
       "          [-1.7109e+01, -7.0645e+00],\n",
       "          [-3.5566e+00, -4.9039e+00]],\n",
       "\n",
       "         [[-6.1112e+00, -7.7936e+00],\n",
       "          [-5.1996e+00, -1.1840e+00],\n",
       "          [-6.8374e+00, -4.8148e+00],\n",
       "          ...,\n",
       "          [-2.3865e+01, -1.0215e+01],\n",
       "          [-1.7141e+01, -7.0665e+00],\n",
       "          [-3.6185e+00, -4.9144e+00]],\n",
       "\n",
       "         [[-6.1288e+00, -7.8111e+00],\n",
       "          [-5.2301e+00, -1.2117e+00],\n",
       "          [-6.8665e+00, -4.8374e+00],\n",
       "          ...,\n",
       "          [-2.3874e+01, -1.0220e+01],\n",
       "          [-1.7156e+01, -7.0747e+00],\n",
       "          [-3.6326e+00, -4.9404e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.6542e+01, -4.9939e+00],\n",
       "          [-1.5181e+01, -9.5722e+00],\n",
       "          [-1.4312e+01, -1.1981e+01],\n",
       "          ...,\n",
       "          [-2.6266e+01, -3.2996e+01],\n",
       "          [-2.2715e+01, -1.3769e+01],\n",
       "          [-1.4512e+01, -1.0687e+01]],\n",
       "\n",
       "         [[ 6.3875e+00, -3.1390e+00],\n",
       "          [ 9.5460e+00, -3.5181e+00],\n",
       "          [ 6.3595e+00, -3.1704e+00],\n",
       "          ...,\n",
       "          [-7.9909e+00, -1.0987e+01],\n",
       "          [ 1.7603e+00, -6.5647e+00],\n",
       "          [ 7.5408e+00, -1.5847e+00]],\n",
       "\n",
       "         [[ 5.5996e+00, -4.5049e+00],\n",
       "          [ 1.4336e+01, -2.9967e+00],\n",
       "          [ 2.3505e+00, -9.3515e+00],\n",
       "          ...,\n",
       "          [-8.5572e-02, -1.5809e+01],\n",
       "          [ 4.5896e+00, -1.2202e+01],\n",
       "          [ 2.3491e+00, -5.1875e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1251e+01, -6.7230e+00],\n",
       "          [ 1.6203e+01,  4.8847e-01],\n",
       "          [ 6.8134e+00, -6.2525e+00],\n",
       "          ...,\n",
       "          [ 1.4396e+00, -1.8704e+01],\n",
       "          [ 4.9036e+00, -9.9583e+00],\n",
       "          [ 9.3855e+00, -6.4508e+00]],\n",
       "\n",
       "         [[ 1.1224e+01, -6.7300e+00],\n",
       "          [ 1.6180e+01,  4.8459e-01],\n",
       "          [ 6.7770e+00, -6.2714e+00],\n",
       "          ...,\n",
       "          [ 1.4179e+00, -1.8726e+01],\n",
       "          [ 4.8654e+00, -9.9864e+00],\n",
       "          [ 9.3779e+00, -6.4665e+00]],\n",
       "\n",
       "         [[ 1.1136e+01, -6.7411e+00],\n",
       "          [ 1.6084e+01,  4.6880e-01],\n",
       "          [ 6.6752e+00, -6.2891e+00],\n",
       "          ...,\n",
       "          [ 1.3603e+00, -1.8745e+01],\n",
       "          [ 4.7735e+00, -9.9949e+00],\n",
       "          [ 9.3153e+00, -6.4936e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.6608e+01, -5.2708e+00],\n",
       "          [-1.5255e+01, -9.8055e+00],\n",
       "          [-1.4360e+01, -1.1973e+01],\n",
       "          ...,\n",
       "          [-2.6357e+01, -3.3092e+01],\n",
       "          [-2.2782e+01, -1.3977e+01],\n",
       "          [-1.4650e+01, -1.0870e+01]],\n",
       "\n",
       "         [[ 4.9157e+00, -9.3664e+00],\n",
       "          [ 7.2010e+00, -9.2743e+00],\n",
       "          [ 4.7185e+00,  1.7580e-01],\n",
       "          ...,\n",
       "          [-9.5167e+00, -1.4992e+01],\n",
       "          [ 6.0077e-01, -1.1675e+01],\n",
       "          [ 4.0914e+00, -7.9087e+00]],\n",
       "\n",
       "         [[ 4.1139e+00, -7.2602e+00],\n",
       "          [ 1.3287e+01, -3.8127e+00],\n",
       "          [ 1.1367e+00, -2.6595e+00],\n",
       "          ...,\n",
       "          [-1.6697e+00, -1.6881e+01],\n",
       "          [ 2.8066e+00, -1.3773e+01],\n",
       "          [-1.7078e-03, -1.0171e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.7947e+00, -1.2303e+01],\n",
       "          [ 1.3895e+01, -5.8083e+00],\n",
       "          [ 8.1493e+00,  8.6192e-02],\n",
       "          ...,\n",
       "          [ 1.5689e+00, -1.3090e+01],\n",
       "          [ 7.5897e+00, -7.9758e+00],\n",
       "          [ 3.0418e+00, -1.0077e+01]],\n",
       "\n",
       "         [[ 9.8228e+00, -1.2313e+01],\n",
       "          [ 1.3913e+01, -5.8287e+00],\n",
       "          [ 8.1466e+00,  5.4753e-02],\n",
       "          ...,\n",
       "          [ 1.6103e+00, -1.3106e+01],\n",
       "          [ 7.6009e+00, -7.9953e+00],\n",
       "          [ 3.0472e+00, -1.0085e+01]],\n",
       "\n",
       "         [[ 9.7585e+00, -1.2328e+01],\n",
       "          [ 1.3837e+01, -5.8450e+00],\n",
       "          [ 8.0620e+00,  2.5904e-02],\n",
       "          ...,\n",
       "          [ 1.5753e+00, -1.3139e+01],\n",
       "          [ 7.5307e+00, -8.0176e+00],\n",
       "          [ 3.0242e+00, -1.0108e+01]]],\n",
       "\n",
       "\n",
       "        [[[-1.6611e+01, -5.5727e+00],\n",
       "          [-1.5278e+01, -1.0159e+01],\n",
       "          [-1.4375e+01, -1.2370e+01],\n",
       "          ...,\n",
       "          [-2.6325e+01, -3.3435e+01],\n",
       "          [-2.2858e+01, -1.4522e+01],\n",
       "          [-1.4633e+01, -1.1137e+01]],\n",
       "\n",
       "         [[ 3.5923e+00, -1.1313e+01],\n",
       "          [ 7.2118e+00, -1.5898e+01],\n",
       "          [ 3.6720e+00, -1.0869e+01],\n",
       "          ...,\n",
       "          [-1.2113e+01, -2.1147e+01],\n",
       "          [-3.3804e+00, -2.0219e+01],\n",
       "          [ 3.0127e+00, -1.3024e+01]],\n",
       "\n",
       "         [[-9.3395e-01, -9.5885e+00],\n",
       "          [ 7.4143e+00, -7.9931e+00],\n",
       "          [-2.0794e+00, -1.0654e+01],\n",
       "          ...,\n",
       "          [-7.2286e+00, -1.8344e+01],\n",
       "          [-2.2808e+00, -1.7879e+01],\n",
       "          [-4.2010e+00, -1.0634e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.4837e+00, -1.5807e+01],\n",
       "          [ 4.1411e+00, -1.3526e+01],\n",
       "          [ 2.6442e-01, -1.5328e+01],\n",
       "          ...,\n",
       "          [-1.2535e+01, -2.1142e+01],\n",
       "          [-8.6686e+00, -2.0874e+01],\n",
       "          [-2.7623e+00, -1.2926e+01]],\n",
       "\n",
       "         [[ 3.4524e+00, -1.5826e+01],\n",
       "          [ 4.0763e+00, -1.3557e+01],\n",
       "          [ 2.1531e-01, -1.5350e+01],\n",
       "          ...,\n",
       "          [-1.2544e+01, -2.1174e+01],\n",
       "          [-8.7064e+00, -2.0875e+01],\n",
       "          [-2.8082e+00, -1.2934e+01]],\n",
       "\n",
       "         [[ 3.3728e+00, -1.5846e+01],\n",
       "          [ 3.9900e+00, -1.3593e+01],\n",
       "          [ 1.2739e-01, -1.5390e+01],\n",
       "          ...,\n",
       "          [-1.2597e+01, -2.1197e+01],\n",
       "          [-8.7685e+00, -2.0908e+01],\n",
       "          [-2.8779e+00, -1.2974e+01]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model.forward(input_ids, attention_mask, target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 50257])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids, labels=target_ids, output_hidden_states=True, attention_mask=attention_mask).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_ = target_ids[torch.arange(4), target_index]\n",
    "targets_ = torch.stack([targets_ for layer in range(2)], dim=1)\n",
    "targets_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50257, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model.get_probs(input_ids, attention_mask, target_ids, target_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "layers = []\n",
    "for layer in range(12):\n",
    "    nl = Linear_lens.from_model(model)\n",
    "    nl.set_parameters({'weight': torch.nn.Parameter(torch.eye(model.config.hidden_size)),\\\n",
    "                        'bias': torch.nn.Parameter(torch.zeros(model.config.hidden_size))})\n",
    "    lens.append(nl)\n",
    "    layers.append(layer)\n",
    "\n",
    "lens_model = Lens_model(lens, layers, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/dataset_test.pkl\", \"rb\") as f:\n",
    "    dataset_test = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/dataset_train.pkl\", \"rb\") as f:\n",
    "    dataset_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = DataLoader(dataset_train, batch_size=4, shuffle=False)\n",
    "data_test = DataLoader(dataset_test, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, input_ids, target_ids, attention_mask, target_index = next(iter(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  16.0838,    6.2038,   -3.5437,  ...,   -6.7148,   -7.2858,\n",
       "             -8.2691],\n",
       "          [  21.1776,    6.2868,   -3.5077,  ...,   -6.6434,   -7.1885,\n",
       "             -8.1944],\n",
       "          [  19.7677,    4.9822,   -5.9960,  ...,   -8.7432,   -9.4221,\n",
       "            -10.4845],\n",
       "          ...,\n",
       "          [  11.1786,   -4.1631,  -11.4905,  ...,  -13.0316,  -13.7163,\n",
       "            -14.8179],\n",
       "          [  13.6240,   -2.5583,  -11.0643,  ...,  -12.2197,  -12.7285,\n",
       "            -13.5820],\n",
       "          [  20.5195,    5.9294,   -3.4365,  ...,   -6.2053,   -6.7674,\n",
       "             -7.7027]],\n",
       "\n",
       "         [[  16.8238,   -8.5267,   -5.0287,  ...,  -71.0284,  -66.2512,\n",
       "            -83.1334],\n",
       "          [  20.4722,   -6.7212,   -3.0400,  ...,  -69.7362,  -63.2890,\n",
       "            -79.7683],\n",
       "          [  22.3595,   -6.9423,   -2.4522,  ...,  -64.7502,  -64.7687,\n",
       "            -84.7910],\n",
       "          ...,\n",
       "          [  22.3544,  -15.8880,  -16.4908,  ...,  -92.0121,  -90.2242,\n",
       "           -104.7963],\n",
       "          [  17.1161,  -13.3273,  -13.2965,  ...,  -85.2986,  -80.7180,\n",
       "            -95.6397],\n",
       "          [  15.7326,   -9.0100,   -5.6064,  ...,  -64.7307,  -61.9305,\n",
       "            -77.0013]],\n",
       "\n",
       "         [[  34.9939,   -6.3608,   -6.2144,  ...,  -64.9087,  -60.7549,\n",
       "            -63.9050],\n",
       "          [  37.8606,   -4.9771,   -5.5866,  ...,  -61.7768,  -57.1388,\n",
       "            -60.8989],\n",
       "          [  33.3534,   -8.4286,   -9.8809,  ...,  -60.2092,  -60.7631,\n",
       "            -67.0714],\n",
       "          ...,\n",
       "          [  39.2036,  -19.6824,  -20.5802,  ...,  -84.3804,  -80.8489,\n",
       "            -78.9678],\n",
       "          [  29.3637,  -20.8892,  -22.3353,  ...,  -81.0184,  -75.7773,\n",
       "            -74.4544],\n",
       "          [  31.2646,   -9.5616,   -9.3731,  ...,  -57.7038,  -54.3079,\n",
       "            -56.8862]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  58.3495,  -15.5341,  -12.8716,  ...,  -67.7758,  -81.4725,\n",
       "           -108.3916],\n",
       "          [  48.5592,   -9.7583,   -9.0729,  ...,  -65.6617,  -77.5427,\n",
       "           -104.6920],\n",
       "          [  49.7401,  -13.1482,  -10.6138,  ...,  -61.2916,  -80.3263,\n",
       "           -110.0464],\n",
       "          ...,\n",
       "          [  53.5119,  -29.5817,  -30.5332,  ...,  -88.6654, -104.0048,\n",
       "           -130.4778],\n",
       "          [  62.6094,  -26.3646,  -25.7854,  ...,  -76.9752,  -89.0539,\n",
       "           -114.0849],\n",
       "          [ 102.0932,   -3.2042,   -4.4254,  ...,  -59.6622,  -75.4387,\n",
       "           -101.6684]],\n",
       "\n",
       "         [[  57.9917,  -15.6029,  -12.9185,  ...,  -67.8030,  -81.4920,\n",
       "           -108.4165],\n",
       "          [  48.0478,   -9.8195,   -9.1302,  ...,  -65.6959,  -77.5697,\n",
       "           -104.7231],\n",
       "          [  49.2444,  -13.2232,  -10.6881,  ...,  -61.3366,  -80.3625,\n",
       "           -110.0844],\n",
       "          ...,\n",
       "          [  53.0683,  -29.6287,  -30.5766,  ...,  -88.6932, -104.0283,\n",
       "           -130.5081],\n",
       "          [  62.2273,  -26.4645,  -25.8640,  ...,  -77.0136,  -89.0823,\n",
       "           -114.1184],\n",
       "          [ 101.7887,   -3.2632,   -4.4811,  ...,  -59.6955,  -75.4656,\n",
       "           -101.6983]],\n",
       "\n",
       "         [[  57.2229,  -15.6126,  -12.9283,  ...,  -67.7932,  -81.5296,\n",
       "           -108.4971],\n",
       "          [  47.4529,   -9.8292,   -9.1442,  ...,  -65.6874,  -77.6042,\n",
       "           -104.8004],\n",
       "          [  48.5970,  -13.2449,  -10.7129,  ...,  -61.3284,  -80.3978,\n",
       "           -110.1580],\n",
       "          ...,\n",
       "          [  52.4887,  -29.6776,  -30.6158,  ...,  -88.6989, -104.0764,\n",
       "           -130.5988],\n",
       "          [  61.4448,  -26.4567,  -25.8547,  ...,  -77.0040,  -89.1242,\n",
       "           -114.2047],\n",
       "          [ 101.3055,   -3.2285,   -4.4726,  ...,  -59.6867,  -75.5022,\n",
       "           -101.7789]]],\n",
       "\n",
       "\n",
       "        [[[  16.0838,    6.8182,   -3.4644,  ...,   -6.0405,   -6.2813,\n",
       "             -7.2003],\n",
       "          [  21.1776,    7.6821,   -3.1773,  ...,   -6.1865,   -6.3067,\n",
       "             -7.2352],\n",
       "          [  19.7677,    6.4664,   -5.6643,  ...,   -8.1612,   -8.3641,\n",
       "             -9.3246],\n",
       "          ...,\n",
       "          [  11.1786,   -2.0111,  -10.7308,  ...,  -12.4735,  -12.8357,\n",
       "            -14.0993],\n",
       "          [  13.6240,   -0.6532,  -10.4918,  ...,  -11.9324,  -12.3269,\n",
       "            -13.3982],\n",
       "          [  20.5195,    7.2137,   -3.1781,  ...,   -5.9413,   -6.1153,\n",
       "             -7.0031]],\n",
       "\n",
       "         [[  16.8238,   -9.7695,   -7.1772,  ...,  -30.6271,  -31.2854,\n",
       "            -48.4104],\n",
       "          [  20.4722,   -7.3156,   -4.5685,  ...,  -37.0506,  -34.6091,\n",
       "            -49.3967],\n",
       "          [  22.3595,   -7.3201,   -3.6509,  ...,  -28.4300,  -31.6442,\n",
       "            -52.5506],\n",
       "          ...,\n",
       "          [  22.3544,  -15.3935,  -15.9559,  ...,  -56.9392,  -52.7491,\n",
       "            -72.5440],\n",
       "          [  17.1161,  -14.5056,  -13.6957,  ...,  -44.3703,  -46.8502,\n",
       "            -65.5143],\n",
       "          [  15.7326,  -10.6332,   -8.5273,  ...,  -38.5136,  -35.5108,\n",
       "            -49.9911]],\n",
       "\n",
       "         [[  34.9939,   -7.1738,   -8.8627,  ...,  -26.1047,  -33.2255,\n",
       "            -51.7140],\n",
       "          [  37.8606,   -5.3801,   -7.6187,  ...,  -31.5402,  -37.0991,\n",
       "            -53.8430],\n",
       "          [  33.3534,   -8.9579,  -12.7735,  ...,  -30.2165,  -36.7914,\n",
       "            -58.1918],\n",
       "          ...,\n",
       "          [  39.2036,  -19.7351,  -21.8168,  ...,  -50.7560,  -52.5689,\n",
       "            -69.1192],\n",
       "          [  29.3637,  -21.2228,  -24.0096,  ...,  -47.9241,  -51.8647,\n",
       "            -68.0166],\n",
       "          [  31.2646,  -10.8173,  -12.5874,  ...,  -31.7073,  -34.6075,\n",
       "            -51.2487]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  58.3495,  -21.0535,  -25.8584,  ...,  -38.0174,  -30.2505,\n",
       "            -66.4794],\n",
       "          [  48.5592,  -14.8226,  -19.7767,  ...,  -42.5428,  -31.2368,\n",
       "            -65.5180],\n",
       "          [  49.7401,  -16.1988,  -21.9565,  ...,  -33.5428,  -29.3753,\n",
       "            -68.3108],\n",
       "          ...,\n",
       "          [  53.5119,  -32.8804,  -36.9065,  ...,  -66.5066,  -58.0795,\n",
       "            -94.7722],\n",
       "          [  62.6094,  -30.9371,  -37.8641,  ...,  -57.2719,  -51.8525,\n",
       "            -87.7988],\n",
       "          [ 102.0932,   -8.7781,  -18.5471,  ...,  -40.6302,  -32.8414,\n",
       "            -66.0720]],\n",
       "\n",
       "         [[  57.9917,  -21.1441,  -25.9051,  ...,  -38.0143,  -30.2176,\n",
       "            -66.3759],\n",
       "          [  48.0478,  -14.9050,  -19.8169,  ...,  -42.5462,  -31.2082,\n",
       "            -65.4191],\n",
       "          [  49.2444,  -16.2997,  -22.0051,  ...,  -33.5439,  -29.3408,\n",
       "            -68.2084],\n",
       "          ...,\n",
       "          [  53.0683,  -32.9669,  -36.9399,  ...,  -66.5189,  -58.0526,\n",
       "            -94.6738],\n",
       "          [  62.2273,  -31.0657,  -37.9239,  ...,  -57.2883,  -51.8301,\n",
       "            -87.7038],\n",
       "          [ 101.7887,   -8.8515,  -18.5906,  ...,  -40.6393,  -32.8188,\n",
       "            -65.9807]],\n",
       "\n",
       "         [[  57.2229,  -21.2275,  -25.9139,  ...,  -38.0258,  -30.2508,\n",
       "            -66.4442],\n",
       "          [  47.4529,  -15.0090,  -19.8427,  ...,  -42.5380,  -31.2244,\n",
       "            -65.4723],\n",
       "          [  48.5970,  -16.4077,  -22.0374,  ...,  -33.5530,  -29.3671,\n",
       "            -68.2686],\n",
       "          ...,\n",
       "          [  52.4887,  -33.0803,  -36.9826,  ...,  -66.5288,  -58.0894,\n",
       "            -94.7459],\n",
       "          [  61.4448,  -31.1407,  -37.9322,  ...,  -57.2883,  -51.8620,\n",
       "            -87.7741],\n",
       "          [ 101.3055,   -8.8844,  -18.5836,  ...,  -40.6374,  -32.8433,\n",
       "            -66.0438]]],\n",
       "\n",
       "\n",
       "        [[[  16.0838,    5.9253,   -3.5597,  ...,   -6.3587,   -7.0612,\n",
       "             -8.5966],\n",
       "          [  21.1776,    5.9955,   -3.5085,  ...,   -6.2098,   -6.7804,\n",
       "             -8.0901],\n",
       "          [  19.7677,    3.9557,   -6.2028,  ...,   -8.3808,   -9.0250,\n",
       "            -10.4032],\n",
       "          ...,\n",
       "          [  11.1786,   -4.2904,  -11.0970,  ...,  -12.2358,  -12.8619,\n",
       "            -14.3357],\n",
       "          [  13.6240,   -1.5146,  -10.5363,  ...,  -11.9691,  -12.6680,\n",
       "            -14.1372],\n",
       "          [  20.5195,    5.3767,   -3.4942,  ...,   -5.9669,   -6.5649,\n",
       "             -7.8914]],\n",
       "\n",
       "         [[  16.8238,   -7.8487,   -7.0281,  ...,  -32.5915,  -40.4198,\n",
       "            -57.6220],\n",
       "          [  20.4722,   -5.4031,   -4.5786,  ...,  -28.8908,  -32.1252,\n",
       "            -46.1582],\n",
       "          [  22.3595,   -6.5040,   -4.7534,  ...,  -27.2598,  -34.7751,\n",
       "            -53.8951],\n",
       "          ...,\n",
       "          [  22.3544,  -14.5979,  -17.7409,  ...,  -44.3741,  -49.7797,\n",
       "            -65.4131],\n",
       "          [  17.1161,  -12.2222,  -12.7240,  ...,  -41.1728,  -49.5852,\n",
       "            -63.8360],\n",
       "          [  15.7326,   -7.8590,   -7.4810,  ...,  -31.0805,  -36.8693,\n",
       "            -52.1525]],\n",
       "\n",
       "         [[  34.9939,   -6.6028,   -7.4873,  ...,  -34.7700,  -41.0165,\n",
       "            -56.5699],\n",
       "          [  37.8606,   -4.6244,   -6.7221,  ...,  -32.3077,  -36.1281,\n",
       "            -47.3868],\n",
       "          [  33.3534,   -8.3514,  -11.4903,  ...,  -32.1959,  -38.7911,\n",
       "            -54.6862],\n",
       "          ...,\n",
       "          [  39.2036,  -21.0021,  -23.1181,  ...,  -49.4996,  -51.9678,\n",
       "            -63.4821],\n",
       "          [  29.3637,  -20.5952,  -22.5177,  ...,  -47.8689,  -53.2629,\n",
       "            -64.4415],\n",
       "          [  31.2646,  -10.0860,  -11.8479,  ...,  -34.1846,  -36.9901,\n",
       "            -50.8174]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  58.3495,  -14.4524,  -13.7815,  ...,  -35.2165,  -43.9068,\n",
       "            -55.0087],\n",
       "          [  48.5592,  -12.1486,  -13.3138,  ...,  -34.2601,  -39.7564,\n",
       "            -48.1200],\n",
       "          [  49.7401,  -14.6268,  -15.4634,  ...,  -31.6726,  -41.3423,\n",
       "            -51.9348],\n",
       "          ...,\n",
       "          [  53.5119,  -25.8827,  -28.6200,  ...,  -46.4054,  -52.1035,\n",
       "            -60.3121],\n",
       "          [  62.6094,  -24.5493,  -23.3342,  ...,  -46.0683,  -54.1478,\n",
       "            -61.8968],\n",
       "          [ 102.0932,   -5.6907,   -8.0027,  ...,  -30.8459,  -38.9003,\n",
       "            -47.8068]],\n",
       "\n",
       "         [[  57.9917,  -14.4840,  -13.7975,  ...,  -35.2404,  -43.9200,\n",
       "            -55.0119],\n",
       "          [  48.0478,  -12.1871,  -13.3340,  ...,  -34.2869,  -39.7749,\n",
       "            -48.1267],\n",
       "          [  49.2444,  -14.6418,  -15.4942,  ...,  -31.7063,  -41.3620,\n",
       "            -51.9408],\n",
       "          ...,\n",
       "          [  53.0683,  -25.8703,  -28.6164,  ...,  -46.4267,  -52.1172,\n",
       "            -60.3170],\n",
       "          [  62.2273,  -24.5855,  -23.3454,  ...,  -46.1061,  -54.1755,\n",
       "            -61.9112],\n",
       "          [ 101.7887,   -5.7002,   -8.0119,  ...,  -30.8810,  -38.9247,\n",
       "            -47.8179]],\n",
       "\n",
       "         [[  57.2229,  -14.5870,  -13.8322,  ...,  -35.2210,  -43.9032,\n",
       "            -55.0006],\n",
       "          [  47.4529,  -12.2828,  -13.3650,  ...,  -34.2668,  -39.7589,\n",
       "            -48.1160],\n",
       "          [  48.5970,  -14.7640,  -15.5317,  ...,  -31.6865,  -41.3463,\n",
       "            -51.9294],\n",
       "          ...,\n",
       "          [  52.4887,  -26.0099,  -28.6745,  ...,  -46.4066,  -52.1020,\n",
       "            -60.3077],\n",
       "          [  61.4448,  -24.6911,  -23.3790,  ...,  -46.0804,  -54.1548,\n",
       "            -61.8986],\n",
       "          [ 101.3055,   -5.7709,   -8.0396,  ...,  -30.8562,  -38.9019,\n",
       "            -47.8029]]],\n",
       "\n",
       "\n",
       "        [[[  16.0838,    4.3407,   -3.7124,  ...,   -6.3650,   -6.6979,\n",
       "             -7.9818],\n",
       "          [  21.1776,    4.3078,   -3.6465,  ...,   -6.3007,   -6.5393,\n",
       "             -7.6923],\n",
       "          [  19.7677,    1.7724,   -6.2167,  ...,   -8.6380,   -8.9625,\n",
       "            -10.2241],\n",
       "          ...,\n",
       "          [  11.1786,   -5.6547,  -11.3336,  ...,  -12.4195,  -12.5974,\n",
       "            -13.8718],\n",
       "          [  13.6240,   -4.5655,  -10.8647,  ...,  -12.0270,  -12.2533,\n",
       "            -13.4627],\n",
       "          [  20.5195,    3.0984,   -3.7154,  ...,   -6.0958,   -6.2730,\n",
       "             -7.3501]],\n",
       "\n",
       "         [[  16.8238,  -12.5156,   -9.7549,  ...,  -22.6498,  -25.2995,\n",
       "            -58.5385],\n",
       "          [  20.4722,   -9.1222,   -7.0337,  ...,  -20.4301,  -21.8666,\n",
       "            -52.7666],\n",
       "          [  22.3595,  -10.3869,   -6.4481,  ...,  -17.5385,  -19.4425,\n",
       "            -55.5427],\n",
       "          ...,\n",
       "          [  22.3544,  -17.8215,  -20.2938,  ...,  -31.4543,  -31.6701,\n",
       "            -65.0924],\n",
       "          [  17.1161,  -17.7141,  -16.8184,  ...,  -26.2013,  -27.4173,\n",
       "            -60.7280],\n",
       "          [  15.7326,  -13.8428,  -11.0695,  ...,  -21.6671,  -22.3348,\n",
       "            -52.4072]],\n",
       "\n",
       "         [[  34.9939,   -6.5784,   -7.6652,  ...,  -30.1119,  -34.4049,\n",
       "            -56.2809],\n",
       "          [  37.8606,   -4.1372,   -6.7427,  ...,  -30.8788,  -32.9997,\n",
       "            -52.0981],\n",
       "          [  33.3534,   -8.4532,  -12.0108,  ...,  -31.8881,  -33.8972,\n",
       "            -57.0000],\n",
       "          ...,\n",
       "          [  39.2036,  -19.1163,  -21.7153,  ...,  -42.7435,  -42.2766,\n",
       "            -60.8856],\n",
       "          [  29.3637,  -21.1623,  -23.0995,  ...,  -44.4614,  -41.9109,\n",
       "            -62.2552],\n",
       "          [  31.2646,  -10.4832,  -11.6667,  ...,  -32.1954,  -31.8242,\n",
       "            -51.8963]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  58.3495,  -18.4420,  -21.6924,  ...,  -43.9273,  -40.7330,\n",
       "            -53.4235],\n",
       "          [  48.5592,  -15.1727,  -19.4741,  ...,  -41.5983,  -35.9092,\n",
       "            -47.4686],\n",
       "          [  49.7401,  -19.6375,  -22.6060,  ...,  -43.7617,  -40.0333,\n",
       "            -54.5232],\n",
       "          ...,\n",
       "          [  53.5119,  -33.7107,  -39.7337,  ...,  -56.1838,  -48.6364,\n",
       "            -61.1646],\n",
       "          [  62.6094,  -30.6399,  -34.2876,  ...,  -55.5863,  -47.1547,\n",
       "            -59.4835],\n",
       "          [ 102.0932,  -12.2396,  -17.9845,  ...,  -42.1225,  -35.3841,\n",
       "            -46.6243]],\n",
       "\n",
       "         [[  57.9917,  -18.4788,  -21.7582,  ...,  -43.9582,  -40.7507,\n",
       "            -53.4400],\n",
       "          [  48.0478,  -15.1884,  -19.5238,  ...,  -41.6191,  -35.9187,\n",
       "            -47.4802],\n",
       "          [  49.2444,  -19.6692,  -22.6766,  ...,  -43.7831,  -40.0419,\n",
       "            -54.5330],\n",
       "          ...,\n",
       "          [  53.0683,  -33.7421,  -39.8009,  ...,  -56.2169,  -48.6571,\n",
       "            -61.1838],\n",
       "          [  62.2273,  -30.6940,  -34.3620,  ...,  -55.6109,  -47.1701,\n",
       "            -59.5010],\n",
       "          [ 101.7887,  -12.2531,  -18.0274,  ...,  -42.1410,  -35.3937,\n",
       "            -46.6354]],\n",
       "\n",
       "         [[  57.2229,  -18.5103,  -21.7159,  ...,  -43.9463,  -40.7530,\n",
       "            -53.4486],\n",
       "          [  47.4529,  -15.1957,  -19.4779,  ...,  -41.6011,  -35.9132,\n",
       "            -47.4824],\n",
       "          [  48.5970,  -19.6633,  -22.5974,  ...,  -43.7617,  -40.0343,\n",
       "            -54.5343],\n",
       "          ...,\n",
       "          [  52.4887,  -33.7952,  -39.7736,  ...,  -56.2117,  -48.6625,\n",
       "            -61.1950],\n",
       "          [  61.4448,  -30.7023,  -34.3046,  ...,  -55.6023,  -47.1745,\n",
       "            -59.5133],\n",
       "          [ 101.3055,  -12.2018,  -17.9563,  ...,  -42.1356,  -35.4002,\n",
       "            -46.6469]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model.forward(input_ids, attention_mask, target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lens_model(\n",
       "  (model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (lens): ParameterList(\n",
       "      (0): Object of type: Linear_lens\n",
       "      (1): Object of type: Linear_lens\n",
       "      (2): Object of type: Linear_lens\n",
       "      (3): Object of type: Linear_lens\n",
       "      (4): Object of type: Linear_lens\n",
       "      (5): Object of type: Linear_lens\n",
       "      (6): Object of type: Linear_lens\n",
       "      (7): Object of type: Linear_lens\n",
       "      (8): Object of type: Linear_lens\n",
       "      (9): Object of type: Linear_lens\n",
       "      (10): Object of type: Linear_lens\n",
       "      (11): Object of type: Linear_lens\n",
       "    (0): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (1): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (2): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (3): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (4): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (5): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (6): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (7): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (8): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (9): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (10): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (11): Linear_lens(\n",
       "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (unembed): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Linear_lens(\n",
       "  (linear): Linear(in_features=10, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_ = Linear_lens(10, 10)\n",
    "lens_.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
